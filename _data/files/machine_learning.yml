
- h2: Machine learning
  question: What is the difference between data science and machine learning
  answer: >
    Data science = statistical analysis + data engineering in order to get 
    information from the data
    <br><br>
    Machine learning = create a model to predict something. You can also define 
    it as teaching computers to learn by examples

- question: What are the typical steps of a machine Learning process?
  answer: > 
    The typical steps of a machine learning process are
    <br>- domain knowledge
    <br>- feature selection
    <br>- choose machine learning algorithm
    <br>- training
    <br>- evaluation
    <br>- optimization
    <br>- testing
   

- question: What is overfitting and what are some techniques for preventing it?
  answer: >
    Overfitting happens when your model works well with the training dataset but
    does not work well with new data, which means the model cannot generalize well. 
    <br>
    To prevent overfitting you can for example use regularization and cross-validation.

- question: What is cross-validation in machine learning?
  answer: > 
    Cross-validation refers to the process of splitting a dataset into a 
    training set (usually 80%) and test set (usually 20%) and evaluate
    the performance of the model with those two datasets. This process
    is usually repeated 10 times.

- question: What is regularization?
  answer: >
    Regularization adds a penalty on the different parameters of the model to reduce the 
    freedom of the model. Regularization is usually done by adding a correction term to 
    the formula for a mathematical model. This correction term penalizes the higher order 
    terms so that the model is forced to be simpler.

- question: What is the curse of dimensionality?
  answer: >
    The curse of dimensionality is a tendency that it is easier to overfit a dataset 
    when there are few points and many features. Data needs to increase exponentially 
    with the number of features in order not to have overfitting.

- question: What is unsupervised learning? Make also some examples
  answer: > 
    Unsupervised learning is a machine learning process with unlabeled data.
    <br><br>
    Some examples of unsupervised learning are
    <br> - Clustering algorithms (K-means, hierarchical custering, Probabilistic clustering)
    <br> - Dimension reduction algorithms (PCA, Single Value Decomposition SVD)

- question: What is reinforcement learning
  answer: >
    It is a machine learning algorithm that receives feedback on his output so that the accuracy
    of the output is improved based on this feedback. Finally the algorithm learns through trial
    and error.

- question: What is supervised learning
  answer: It is a machine learning process with a labeled training dataset.

- question: What are the two main types of supervised learning algorithms?
  answer: >
    Supervised machine learning algorithms are mainly classified 
    into classification and regression.


- h3: Evaluate machine learning methods
  question: What is bias in a machine learning model?
  answer: >
    Bias is the error that is introduced by analyzing a complex model using a too simple model. 
    In other words bias is the inability of the model to capture the real nature of the true 
    relationship in the data.

- question: What does high bias mean for my model?
  answer: High bias means the model is underfitting the data.

- question: What is the variance of a machine learning model?
  answer: > 
    Variance is the amount that the estimate of the target function will change if different training 
    data was used.

- question: What does high variance mean for my model?
  answer: > 
    High variance means the model is overfitting, ie small changes in the training data set lead 
    to big changes in the output of the model.


- question: What matrix do you construct to evaluate the performance of a classifier?
  answer: >
    To evaluate the performance of a classifier you construct a confusion matrix
    <table>
      <tr>
        <td></td>
        <th>y = 1</th> 
        <th>y = -1</th>
      </tr>
      <tr>
        <td>y# = 1</td>
        <td>TP</td> 
        <td>FP</td>
      </tr>
      <tr>
        <td>y# = -1</td>
        <td>FN</td> 
        <td>TN</td>
      </tr>
    </table>
    <br>
    where 
    y = actual label, y# = predicted label, TP = true positives, FP = false positives, FN = false negatives
    TN = true negatives.

- question: Can you mention some numerican quantities used to evaluate classifiers?
  answer: >
    misclassification error or accuracy = (FP + FN) / n
    <br>true positive rate or sentitivity = TP / (TP + FN)
    <br>true negative rate or specificity = TN / (TN + FP)
    <br>Precision  = TP / (TP + FP)
    <br>False positive rate (FNR)  = FP / (TN + FP)
    <br>False  negative rate (FNR)  = FN / (TP + FN)

- question: To evaluate a generic ML model what numerical quantity do you typically use?
  answer: You would the use misclassification error or accuracy

- question: To evaluate a ML model for medicine what numerical quantities do you typically use?
  answer: Doctors would use sensitivity and specificity.

- question: If you want to evaluate a classifier with a curve what do you use?
  answer: >
    You can use an ROC curve. An ROC curve answers to the question 
    â€œfor a particular false positive rate what is the corresponding true positive rate?
  image: roc_curve.png

- h3: Naive Bayes
  question: What is Naive Bayes?
  answer: >
    Naive Bayes is a supervised machine learning algorithm based on the Bayes theorem that is used
    to solve classification problems.

- question: Why is Naive Bayes called "naive"?
  answer: >
    Because the Naive Bayes is based on the idea that the predictor variables are independent of 
    each other while in nature this is oft not the case.

- question: What is the Bayes theorem?
  answer: >
    The Bayes theorem is a mathematical formula for finding P(A|B) from P(B|A).
    The formula is 
    <br><br>
    P(A|B) = P(B|A) * P(A) / P(B)


- question: What are the main advantages of Naive Bayes?
  answer: >
    The Naive Bayes is a relatively simple and very quick algorithm since it is a probabilistic 
    model that does not require a training step. This makes it very scalable.

- question: When is the Naive Bayes usually used?
  answer: > 
    Naive Bayes is often used in <br>
    - text classification like spam filter<br>
    - real-time classification since it is fast<br>
    - multi-class prediction

- question: When Naive Bayes is used with numerical variables, what condition is assumed on the data?
  answer: >
    Numerical variables used in Naive Bayes are expected to have a normal distribution.
    This is not always the case in practice.

- question: How does the Naive Bayes perform with categorical variables?
  answer: > 
    It performs well with categorical variables since no assumpion is made on
    the data distribution. By contrast with numerical variables a normal distribution
    is assumed.

- h3: Regression
  question: What do you predict with linear regression?
  answer: Linear regression predicts a real value

- question: What are the most common techniques used for computing the coefficients in linear regression?
  answer: >
    The most common techniques used for computing the coefficients in linear regression are 
    <br> - Ordinary Least Squares. Seeks to minimize the sum of the squared residuals, ie the distance 
    between the points and the regression line.
    <br><br> - Gradient descendent. Works by inizializing randomly the coefficients. A learning rate is 
    used as a scale factor and the coefficients are updated in the direction towards minimizing the error. 
    The process is repeated until a minimum sum squared error is achieved or no further improvement is 
    possible.

- question: What is logistic regression?
  answer: >
    It is a statistical technique that is used to analyze a dataset and predict the binary outcome. 
    The outcome has to be a binary outcome that is either zero or one or a yes or no. 
    In other words the output of a logistic regression is always categorical (= discrete)


- question: What do you predict with logistic regression?
  answer: >
    Logistic regression predicts the probabilty that a variable has one value or another. 
    Thus it is a binary variable.